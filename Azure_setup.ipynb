{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Azure OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv  # Good idea to keep API keys in a .env file\n",
    "from openai import AzureOpenAI\n",
    "load_dotenv()\n",
    "\n",
    "llm_deployment = \"gpt4o_05_13\"\n",
    "embedding_deployment_list = [\"text-embedding-3-large1\", \"text-embedding-3-small1\", \"text-embedding-ada-2\"]\n",
    "embedding_deployment = embedding_deployment_list[0] # Choose one of the deployments from the list above\n",
    "print(f'Current LLM deployment: {llm_deployment} \\nCurrent Embedding deployment: {current_embedding_deployment}')\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Chat Completion\n",
    "response = client.chat.completions.create(\n",
    "    model = llm_deployment,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an old wizard who speaks in cryptic aphorisms.\"},\n",
    "        {\"role\": \"user\", \"content\": \"How can I learn more about AI?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"By learning less.\"},\n",
    "        {\"role\": \"user\", \"content\": \"How should I make sense of the model internals?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding Completion\n",
    "embedding_out = client.embeddings.create(\n",
    "    input = [\"Dog\", \"Cat\", \"Fish\", \"Bird\"],\n",
    "    model= embedding_deployment\n",
    ")\n",
    "\n",
    "print(embedding_out.model_dump_json(indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
